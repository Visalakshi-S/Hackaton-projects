{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Customer segmentation_unsupervised ML.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBjkEQeGW4hn"
      },
      "source": [
        "# import packages\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt \r\n",
        "from sklearn.cluster import KMeans\r\n",
        "from sklearn.decomposition import PCA\r\n",
        "\r\n",
        "# Load Offers\r\n",
        "path=\"/content/drive/MyDrive/Colab_Notebooks/clustering data set.xlsx\"\r\n",
        "offers = pd.read_excel(path, sheet_name=0)\r\n",
        "\r\n",
        "# Load Transactions\r\n",
        "transactions = pd.read_excel(path, sheet_name=1)\r\n",
        "transactions['n'] = 1\r\n",
        "\r\n",
        "# Merge dataframes\r\n",
        "df = pd.merge(transactions, offers)\r\n",
        "\r\n",
        "# Look at the first 5 rows\r\n",
        "print(df.head())\r\n",
        "\r\n",
        "# create pivot table\r\n",
        "matrix = df.pivot_table(index='Customer Last Name', columns='Offer #', values='n')\r\n",
        "\r\n",
        "# replace missing values with 0\r\n",
        "matrix.fillna(0, inplace=True)\r\n",
        "\r\n",
        "# reindex pivot table\r\n",
        "matrix.reset_index(inplace=True)\r\n",
        "\r\n",
        "# display first 5 rows\r\n",
        "print(matrix.head())\r\n",
        "\r\n",
        "# initialize KMeans object\r\n",
        "cluster = KMeans(n_clusters=5, init='k-means++', max_iter=300, n_init=10, random_state=0)\r\n",
        "\r\n",
        "# create 'cluster' column\r\n",
        "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\r\n",
        "\r\n",
        "print(matrix.head())\r\n",
        "\r\n",
        "# initialize pca object with 2 components\r\n",
        "pca = PCA(n_components=2, random_state=0)\r\n",
        "\r\n",
        "# create 'x' and 'y' columns donoting observation locations in decomposed form\r\n",
        "matrix['x'] = pca.fit_transform(matrix[matrix.columns[1:]])[:,0]\r\n",
        "matrix['y'] = pca.fit_transform(matrix[matrix.columns[1:]])[:,1]\r\n",
        "\r\n",
        "# dataframe to visualize clusters by customer names\r\n",
        "clusters = matrix.iloc[:,[0,33,34,35]]\r\n",
        "\r\n",
        "# visualize clusters\r\n",
        "clusters.plot.scatter(x='x', y='y', c='cluster', colormap='viridis')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# merge 'clusters' and 'transactions'\r\n",
        "data = pd.merge(clusters, transactions)\r\n",
        "print(data.head())\r\n",
        "print('='*25)\r\n",
        "\r\n",
        "\r\n",
        "# merge `data` and `offers`\r\n",
        "data = pd.merge(offers, data)\r\n",
        "print(data.head())\r\n",
        "print('='*25)\r\n",
        "\r\n",
        "# initialzie empty dictionary\r\n",
        "champagne = {}\r\n",
        "\r\n",
        "# iterate over every cluster\r\n",
        "for val in data.cluster.unique():\r\n",
        "    # observation falls in that cluster\r\n",
        "    new_df = data[data.cluster == val]\r\n",
        "    # sort cluster according to type of 'Varietal'\r\n",
        "    counts = new_df['Varietal'].value_counts(ascending=False)\r\n",
        "    # check if 'Champagne' is ordered mostly\r\n",
        "    if counts.index[0] == 'Champagne':\r\n",
        "        # add it to 'champagne'\r\n",
        "        champagne[val] = (counts[0])\r\n",
        "\r\n",
        "# get cluster with maximum orders of 'Champagne' \r\n",
        "cluster_champagne = max(champagne, key=champagne.get)\r\n",
        "\r\n",
        "# print out cluster number\r\n",
        "print(cluster_champagne)\r\n",
        "\r\n",
        "# empty dictionary\r\n",
        "discount = {} \r\n",
        "\r\n",
        "# iterate over cluster numbers\r\n",
        "for val in data.cluster.unique():\r\n",
        "    # dataframe for every cluster\r\n",
        "    new_df = data[data.cluster == val]\r\n",
        "    # average discount for cluster\r\n",
        "    counts = new_df['Discount (%)'].values.sum() / len(new_df)\r\n",
        "    # adding cluster number as key and average discount as value \r\n",
        "    discount[val] = counts\r\n",
        "\r\n",
        "# cluster with maximum average discount\r\n",
        "cluster_discount = max(discount, key=discount.get)\r\n",
        "print(cluster_discount)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}